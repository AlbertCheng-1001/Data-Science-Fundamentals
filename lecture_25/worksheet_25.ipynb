{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Worksheet 25\n",
    "\n",
    "Name:  Albert Cheng\n",
    "UID: U55565220\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Advanced Neural Networks\n",
    "\n",
    "## Advanced Neural Networks\n",
    "\n",
    "Nothing to do in this worksheet except follow along in lecture / use this code to better understand Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Encoder Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-07 18:45:43.786121: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.boat.dat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrobenius\u001b[39m(X, Y):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(X \u001b[38;5;241m-\u001b[39m Y, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m boat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloadtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.boat.dat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m     38\u001b[0m _ \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimshow(boat,cmap \u001b[38;5;241m=\u001b[39m cm\u001b[38;5;241m.\u001b[39mGreys_r)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/npyio.py:1373\u001b[0m, in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, quotechar, like)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(delimiter, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m   1371\u001b[0m     delimiter \u001b[39m=\u001b[39m delimiter\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1373\u001b[0m arr \u001b[39m=\u001b[39m _read(fname, dtype\u001b[39m=\u001b[39;49mdtype, comment\u001b[39m=\u001b[39;49mcomment, delimiter\u001b[39m=\u001b[39;49mdelimiter,\n\u001b[1;32m   1374\u001b[0m             converters\u001b[39m=\u001b[39;49mconverters, skiplines\u001b[39m=\u001b[39;49mskiprows, usecols\u001b[39m=\u001b[39;49musecols,\n\u001b[1;32m   1375\u001b[0m             unpack\u001b[39m=\u001b[39;49munpack, ndmin\u001b[39m=\u001b[39;49mndmin, encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1376\u001b[0m             max_rows\u001b[39m=\u001b[39;49mmax_rows, quote\u001b[39m=\u001b[39;49mquotechar)\n\u001b[1;32m   1378\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/npyio.py:992\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(fname, delimiter, comment, quote, imaginary_unit, usecols, skiplines, max_rows, converters, ndmin, unpack, dtype, encoding)\u001b[0m\n\u001b[1;32m    990\u001b[0m     fname \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mfspath(fname)\n\u001b[1;32m    991\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fname, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 992\u001b[0m     fh \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlib\u001b[39m.\u001b[39;49m_datasource\u001b[39m.\u001b[39;49mopen(fname, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding)\n\u001b[1;32m    993\u001b[0m     \u001b[39mif\u001b[39;00m encoding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    994\u001b[0m         encoding \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(fh, \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlatin1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/_datasource.py:193\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mOpen `path` with `mode` and return the file object.\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    192\u001b[0m ds \u001b[39m=\u001b[39m DataSource(destpath)\n\u001b[0;32m--> 193\u001b[0m \u001b[39mreturn\u001b[39;00m ds\u001b[39m.\u001b[39;49mopen(path, mode, encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/lib/_datasource.py:530\u001b[0m, in \u001b[0;36mDataSource.open\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[39mif\u001b[39;00m ext \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbz2\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    529\u001b[0m         mode\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 530\u001b[0m     \u001b[39mreturn\u001b[39;00m _file_openers[ext](found, mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m    531\u001b[0m                               encoding\u001b[39m=\u001b[39;49mencoding, newline\u001b[39m=\u001b[39;49mnewline)\n\u001b[1;32m    532\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m not found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.boat.dat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras, norm\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Principal Component Extraction using Neural Net\n",
    "#\n",
    "# \n",
    "#       x[0]            x[0]' \n",
    "#          \\            /\n",
    "#           \\          /\n",
    "#            \\        /\n",
    "#       x[1]  \\      /  x[1]'\n",
    "#            \\ \\    / /   \n",
    "#         .    \\\\  //    .\n",
    "#         .  --- z ---   .\n",
    "#         .    //  \\\\    .\n",
    "#            / /    \\ \\\n",
    "#      x[n-1] /      \\ x[n-1]' \n",
    "#            /        \\\n",
    "#           /          \\\n",
    "#       x[n]             x[n]'\n",
    "#\n",
    "# where x' is the approximation of x based on the z components extracted\n",
    "\n",
    "# MODIFY THIS LINE\n",
    "RANK = 10\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    return norm(y_true - y_pred, ord='euclidean')\n",
    "\n",
    "def frobenius(X, Y):\n",
    "    return np.linalg.norm(X - Y, ord='fro')\n",
    "\n",
    "boat = np.loadtxt('.boat.dat')\n",
    "plt.figure()\n",
    "_ = plt.imshow(boat,cmap = cm.Greys_r)\n",
    "plt.show()\n",
    "\n",
    "u,s,vt=np.linalg.svd(boat,full_matrices=False)\n",
    "_ = plt.plot(s)\n",
    "plt.title('Singular values of boat image')\n",
    "plt.show()\n",
    "\n",
    "# construct a rank-RANK version of the boat\n",
    "scopy = s.copy()\n",
    "scopy[RANK:]=0\n",
    "boatApprox = u.dot(np.diag(scopy)).dot(vt)\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(layers.Dense(RANK, use_bias=False, input_dim=len(boat)))\n",
    "model.add(layers.Dense(len(boat), use_bias=False))\n",
    "model.compile(loss=custom_loss)\n",
    "\n",
    "history = model.fit(boat, boat, batch_size=50, epochs=500)\n",
    "\n",
    "boatNNApprox = model.predict(boat)\n",
    "\n",
    "print(\"Frobenius Distance between boat and rank-\"+str(RANK)+\" approximation: \", frobenius(boat, boatApprox))\n",
    "print(\"Frobenius Distance between boat and NN output with 1 hidden layer of \"+str(RANK)+\" neurons: \", frobenius(boat, boatNNApprox))\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(boatApprox,cmap = cm.Greys_r)\n",
    "plt.title('Rank ' + str(RANK) + ' SVD Boat')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(boatNNApprox,cmap = cm.Greys_r)\n",
    "plt.title('Rank ' + str(RANK) + ' NN Boat')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(boat,cmap = cm.Greys_r)\n",
    "plt.title('Original Boat')\n",
    "\n",
    "_ = plt.subplots_adjust(wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      " 53387264/170498071 [========>.....................] - ETA: 5s"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from keras import utils\n",
    "from keras.datasets import cifar10\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "\n",
    "X_train = X_train.astype('float32')/255.0\n",
    "X_test = X_test.astype('float32')/255.0\n",
    "mean = np.mean(X_train, axis = (0,1,2))\n",
    "std = np.std(X_train, axis = (0,1,2))\n",
    "X_train = (X_train-mean)/(std+1e-7)\n",
    "X_test = (X_test-mean)/(std+1e-7)\n",
    "\n",
    "fig, axes = plt.subplots(ncols=3, nrows=3, figsize=(8, 8))\n",
    "index = 0\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        axes[i,j].set_title(labels[y_train[index][0]])\n",
    "        axes[i,j].imshow(X_train[index])\n",
    "        axes[i,j].get_xaxis().set_visible(False)\n",
    "        axes[i,j].get_yaxis().set_visible(False)\n",
    "        index += 1\n",
    "plt.show()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, utils.to_categorical(y_train), epochs=10, batch_size=1000, validation_data=(X_test, utils.to_categorical(y_test)))\n",
    "\n",
    "plt.plot(history.history[\"accuracy\"], label='train')\n",
    "plt.plot(history.history[\"val_accuracy\"], label='test')\n",
    "plt.title('Classification Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"loss\"], label='train')\n",
    "plt.plot(history.history[\"val_loss\"], label='test')\n",
    "plt.title('Cross Entropy Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, np.argmax(predictions,axis=1))\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(cm, cbar=False, xticklabels=labels, yticklabels=labels, fmt='d', annot=True, cmap=plt.cm.Blues)\n",
    "plt.title('RGB Network Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
